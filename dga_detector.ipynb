{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bd0b9f0",
   "metadata": {},
   "source": [
    "1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89d3b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from pandas import read_csv, concat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import tldextract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ad58b",
   "metadata": {},
   "source": [
    "2. Read DGA and non-DGA datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcaa996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitDomains = read_csv('legit.csv',names=['domain'])\n",
    "dgaDomains = read_csv('dga.csv',names=['domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfbd66",
   "metadata": {},
   "source": [
    "3. Extract top-level Domains (TLD) and clean the dataset from undesired characters,\n",
    "To do it we use \"tldextract\" that accurately separates the gTLD or ccTLD (generic or country code top-level domain) from the registered domain and subdomains of a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fc400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitDomains['tld'] = [tldextract.extract(d).domain for d in legitDomains['domain']]\n",
    "dgaDomains['tld'] = [tldextract.extract(d).domain for d in dgaDomains['domain']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b0600",
   "metadata": {},
   "source": [
    "4. Regex function to clean domains of unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdee3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitDomains = legitDomains[~legitDomains['tld'].str.contains('\\`|\\.')]\n",
    "dgaDomains = dgaDomains[~dgaDomains['tld'].str.contains('\\`|\\.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ffd96",
   "metadata": {},
   "source": [
    "5. Remove duplicates and label each domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a2f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitDomains = legitDomains.drop_duplicates()\n",
    "dgaDomains = dgaDomains.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01d843",
   "metadata": {},
   "source": [
    "6. Tag with labels 1 and 0 the legit and dga domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc3d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitDomains['label'] = 0\n",
    "dgaDomains['label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429052fd",
   "metadata": {},
   "source": [
    "7. Combine two datasets and shuffle them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "999394af",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDomains = concat([legitDomains, dgaDomains], ignore_index=True)\n",
    "allDomains = allDomains.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f0f9ad",
   "metadata": {},
   "source": [
    "8. Asignation of the variables X and y, X is the dataset and y is the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "804be9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = allDomains['tld']\n",
    "y = allDomains['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7065a3a",
   "metadata": {},
   "source": [
    "9. Assign a number for each possible character in the domains and determine the maximum domain length:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910cda8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': 1, 'l': 2, '1': 3, 'b': 4, 'm': 5, 'j': 6, '5': 7, 'h': 8, '6': 9, 'e': 10, 'g': 11, 'a': 12, 'v': 13, '3': 14, 'u': 15, 'k': 16, 'i': 17, 's': 18, 'p': 19, 'r': 20, '-': 21, 'o': 22, '0': 23, 'x': 24, 'd': 25, 't': 26, '7': 27, 'q': 28, 'y': 29, '2': 30, '9': 31, 'n': 32, 'c': 33, 'f': 34, '4': 35, 'z': 36, '8': 37}\n"
     ]
    }
   ],
   "source": [
    "validChars = {'w': 1, 'l': 2, '1': 3, 'b': 4, 'm': 5, 'j': 6, '5': 7, 'h': 8, '6': 9, 'e': 10, 'g': 11, 'a': 12, 'v': 13, '3': 14, 'u': 15, 'k': 16, 'i': 17, 's': 18, 'p': 19, 'r': 20, '-': 21, 'o': 22, '0': 23, 'x': 24, 'd': 25, 't': 26, '7': 27, 'q': 28, 'y': 29, '2': 30, '9': 31, 'n': 32, 'c': 33, 'f': 34, '4': 35, 'z': 36, '8': 37}\n",
    "print(validChars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e87f7",
   "metadata": {},
   "source": [
    "10. Encode each domain and build a testing and evaluating dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283bde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[validChars[y] for y in x ] for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bfaab6",
   "metadata": {},
   "source": [
    "11. Complete with 0 the vector to the maximun domain lenght "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25ba8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxFeatures= len(validChars) + 1\n",
    "maxlen = np.max([len(x) for x in X])\n",
    "X = pad_sequences(X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987cd806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 20, 12,  2],\n",
       "       [ 0,  0,  0, ...,  8, 18, 33],\n",
       "       [ 0,  0,  0, ..., 11, 25, 19],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 12, 26, 10],\n",
       "       [ 0,  0,  0, ..., 10, 16, 18],\n",
       "       [ 0,  0,  0, ..., 22, 18, 16]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9917b502",
   "metadata": {},
   "source": [
    "12. Apply the Sklearn function \"train_test_split\" that split arrays or matrices into random train and test subsets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55cba07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9bcfc9",
   "metadata": {},
   "source": [
    "13. Build and compile LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c57c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(maxFeatures, 128, input_length=maxlen))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=True), optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79f9e6",
   "metadata": {},
   "source": [
    "14. Train the model for 15 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "724a1c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7962/7962 [==============================] - 396s 50ms/step - loss: 0.3964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c443c4190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=16, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67780bd8",
   "metadata": {},
   "source": [
    "15. Test with the domain inqduvhqfo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a0ef945",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = [[validChars[ch] for ch in tldextract.extract('inqduvhqfo.com').domain]]\n",
    "domain = pad_sequences(domain, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dd30da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(model.predict(domain)),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0771b1ae",
   "metadata": {},
   "source": [
    "16. Creating the test for the model with the training dataset X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "453dfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b92d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.       ],\n",
       "       [ 1.       ],\n",
       "       [ 1.       ],\n",
       "       ...,\n",
       "       [ 1.       ],\n",
       "       [-0.9994314],\n",
       "       [-1.       ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef84a2",
   "metadata": {},
   "source": [
    "17. Definition of the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04660ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, probs > 0.5).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbed70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 13410\n",
      "TN: 15813\n",
      "FP: 157\n",
      "FN: 2467\n",
      "\n",
      "FP rate: 0.983%\n",
      "FN rate: 15.538%\n",
      "\n",
      "Sensitivity: 0.845%\n",
      "Specificity: 0.990%\n",
      "Acurracy: 0.918%\n",
      "\n",
      "AUC: 0.960%\n"
     ]
    }
   ],
   "source": [
    "print('TP: %d\\nTN: %d\\nFP: %d\\nFN: %d\\n' %(tp, tn, fp, fn))\n",
    "print('FP rate: %.3f%%\\nFN rate: %.3f%%\\n' % (fp / (fp + tn) * 100, fn / (fn + tp) *100))\n",
    "\n",
    "print('Sensitivity: %.3f%%\\nSpecificity: %.3f%%\\nAcurracy: %.3f%%\\n' % (\n",
    "    tp / (tp + fn),\n",
    "    tn / (tn + fp),\n",
    "    (tp + tn) / (tp + tn + fp + fn)\n",
    "))\n",
    "\n",
    "print('AUC: %.3f%%' % roc_auc_score(y_test, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e920994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./gpu_test_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
